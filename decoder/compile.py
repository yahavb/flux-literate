import argparse
import copy
import os
import torch
import torch_neuronx
from diffusers import FluxPipeline
from model import TracingVAEDecoderWrapper

COMPILER_WORKDIR_ROOT = os.path.dirname(__file__)


def trace_vae(height, width, instance_type):
    compiler_args = "--model-type=unet-inference"
    if instance_type == "trn2":
        os.environ["NEURON_RT_VIRTUAL_CORE_SIZE"] = "2"
        compiler_args = "--target=trn2 --lnc=2 --model-type=unet-inference"
    pipe = FluxPipeline.from_pretrained(
        "black-forest-labs/FLUX.1-dev",
        torch_dtype=torch.float32,
        cache_dir="flux_hf_cache_dir")
    decoder = copy.deepcopy(pipe.vae.decoder)
    decoder = TracingVAEDecoderWrapper(decoder)
    del pipe

    latents = torch.rand([1, 16, height // 8, width // 8],
                         dtype=torch.bfloat16)

    decoder_neuron = torch_neuronx.trace(
        decoder,
        latents,
        compiler_workdir=os.path.join(COMPILER_WORKDIR_ROOT,
                                      'compiler_workdir'),
        compiler_args=compiler_args,
        inline_weights_to_neff=False,
        )

    torch_neuronx.async_load(decoder_neuron)

    compiled_model_path = os.path.join(COMPILER_WORKDIR_ROOT, 'compiled_model')
    if not os.path.exists(compiled_model_path):
        os.mkdir(compiled_model_path)
    decoder_filename = os.path.join(COMPILER_WORKDIR_ROOT,
                                    'compiled_model/model.pt')
    torch.jit.save(decoder_neuron, decoder_filename)

    del decoder
    del decoder_neuron


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-hh",
        "--height",
        type=int,
        default=1024,
        help="height of images to be generated by compilation of this model"
    )
    parser.add_argument(
        "-w",
        "--width",
        type=int,
        default=1024,
        help="width of images to be generated by compilation of this model"
    )
    parser.add_argument(
        "-i",
        "--instance_type",
        type=str,
        default="trn2",
        help="instance type to run this model on, e.g. trn1, trn2"
    )
    args = parser.parse_args()
    trace_vae(args.height, args.width, args.instance_type)

